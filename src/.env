# Models run slightly faster, like 5-10%
GGML_CUDA_GRAPH_OPT=1

# Backend binary locations
LLAMA_BACKEND=./vendor/bin/llama.cpp
WHISPER_BACKEND=./vendor/bin/whisper.cpp